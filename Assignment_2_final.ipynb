{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language Modeling and Smoothing\n",
    "1. Download any of these text books from Project Gutenberg\n",
    "a. Alice in Wonderland: ​ ​Alice’s Adventures in Wonderland\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "url=\"http://www.gutenberg.org/files/11/11-0.txt\" # url for downloading \"alice_in_wonderland.txt\"\n",
    "response = request.urlopen(url)\n",
    "whole_text = response.read().decode('utf8')\n",
    "# Now Compute Tokens\n",
    "#from nltk import word_tokenize\n",
    "#tokens = word_tokenize(whole_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Parse the dataset into sentences using sentence ​tokenizer ​ and divide it into 80/20 ratio. Keep\n",
    "80% dataset for training N-grams and keep 20% for test. You can filter out unnecessary symbols,\n",
    "newlines, etc. You can add symbols <s> and </s> to mark sentence start and end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Total Sentences: 1093\n",
      "Length of train_samples sentences: 874\n",
      "Length of test_samples sentences: 219\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenized_list = sent_tokenize(whole_text)\n",
    "print('Length of Total Sentences:',len(sent_tokenized_list))\n",
    "import random\n",
    "import math\n",
    "\n",
    "random.shuffle(sent_tokenized_list) # randomly suffle the list\n",
    "train_percentage=80\n",
    "test_percentage=20\n",
    "\n",
    "no_of_training_sample=math.floor((train_percentage*len(sent_tokenized_list))/100)\n",
    "train_samples=sent_tokenized_list[:no_of_training_sample] # This variable store the 80% of the training sentences\n",
    "test_samples=sent_tokenized_list[no_of_training_sample:]# This variable store the 20% of the training sentences\n",
    "print('Length of train_samples sentences:',len(train_samples))\n",
    "print('Length of test_samples sentences:',len(test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An\\r\\ninvitation for the Duchess to play croquet.’\\r\\n\\r\\nThen they both bowed low, and their curls got entangled together.',\n",
       " '‘That’s none of YOUR business, Two!’ said Seven.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples[2:4] # print some sample train samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add start and end symbols to the train and test samples (same thing can be done on 'sent_tokenized_list')\n",
    "for num in range(len(train_samples)):\n",
    "    train_samples[num]='<s> '+train_samples[num]+' </s>'\n",
    "    \n",
    "for num in range(len(test_samples)):\n",
    "    test_samples[num]='<s> '+test_samples[num]+' </s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> An\\r\\ninvitation for the Duchess to play croquet.’\\r\\n\\r\\nThen they both bowed low, and their curls got entangled together. </s>',\n",
       " '<s> ‘That’s none of YOUR business, Two!’ said Seven. </s>']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-Compute MLE for unigram, bigram, trigrams and quadgrams. How many n-grams are possible\n",
    "and how many actually exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: 29465\n",
      "Type: 6019\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "# Now Compute Tokens for checking purpose\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "tokens_tmp =whole_text.split()\n",
    "\n",
    "print('Tokens:',len(tokens_tmp))\n",
    "\n",
    "# Now compute type\n",
    "import numpy as np\n",
    "type_tmp=np.unique(tokens_tmp)\n",
    "print(\"Type:\",len(type_tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible unigrams =6019\n",
      "Total unigrams =6019\n"
     ]
    }
   ],
   "source": [
    "# MLE for unigram \n",
    "from nltk.probability import FreqDist\n",
    "output = list(ngrams(whole_text.split(), 1))\n",
    "fdist1 = FreqDist(output)\n",
    "# Uncomment the following two lines to print the probablities\n",
    "#for item in fdist1.keys():\n",
    "#    print('Prob of', item, 'is', fdist1[item]/len(fdist1))\n",
    "\n",
    "# mle_unigram is a dictionary, which stores n-grams and corresponding probablities\n",
    "mle_unigram={}\n",
    "for key, value in fdist1.items():\n",
    "    mle_unigram[key]=fdist1[key]/len(output)\n",
    "    \n",
    "print(\"Possible unigrams ={}\".format(len(type_tmp))) #type_tmp is vocabulary size\n",
    "print(\"Total unigrams ={}\".format(len(mle_unigram)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible bigrams =36228361\n",
      "Total bigrams =19419\n"
     ]
    }
   ],
   "source": [
    "# MLE for bigram \n",
    "output = list(ngrams(whole_text.split(), 2))\n",
    "fdist1 = FreqDist(output)\n",
    "# Uncomment the following two lines to print the probablities\n",
    "#for item in fdist1.keys():\n",
    "#    print('Prob of', item, 'is', fdist1[item]/len(fdist1))\n",
    "\n",
    "# mle_bigram is a dictionary, which stores n-grams and corresponding probablities\n",
    "mle_bigram={}\n",
    "for key, value in fdist1.items():\n",
    "    mle_bigram[key]=fdist1[key]/len(output)\n",
    "    \n",
    "print(\"Possible bigrams ={}\".format(len(type_tmp)**2))\n",
    "print(\"Total bigrams ={}\".format(len(mle_bigram)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible trigrams =218058504859\n",
      "Total trigrams =26595\n"
     ]
    }
   ],
   "source": [
    "# MLE for trigram \n",
    "output = list(ngrams(whole_text.split(), 3))\n",
    "fdist1 = FreqDist(output)\n",
    "# Uncomment the following two lines to print the probablities\n",
    "#for item in fdist1.keys():\n",
    "#    print('Prob of', item, 'is', fdist1[item]/len(fdist1))\n",
    "    \n",
    "# mle_trigram is a dictionary, which stores n-grams and corresponding probablities    \n",
    "mle_trigram={}\n",
    "for key, value in fdist1.items():\n",
    "    mle_trigram[key]=fdist1[key]/len(output)\n",
    "    \n",
    "    \n",
    "print(\"Possible trigrams ={}\".format(len(type_tmp)**3))\n",
    "print(\"Total trigrams ={}\".format(len(mle_trigram)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible quadgrams =1312494140746321\n",
      "Total quadgrams =28552\n"
     ]
    }
   ],
   "source": [
    "# MLE for quadgram \n",
    "output = list(ngrams(whole_text.split(), 4))\n",
    "fdist1 = FreqDist(output)\n",
    "# Uncomment the following two lines to print the probablities\n",
    "#for item in fdist1.keys():\n",
    "#    print('Prob of', item, 'is', fdist1[item]/len(fdist1))\n",
    "\n",
    "# mle_quadgram is a dictionary, which stores n-grams and corresponding probablities    \n",
    "mle_quadgram={}\n",
    "for key, value in fdist1.items():\n",
    "    mle_quadgram[key]=fdist1[key]/len(fdist1)\n",
    "\n",
    "    \n",
    "print(\"Possible quadgrams ={}\".format(len(type_tmp)**4))\n",
    "print(\"Total quadgrams ={}\".format(len(mle_quadgram)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Develop a system that has two functions:\n",
    "\n",
    "a. Generator(model_name): generates sentences by utilizing MLEs from specified\n",
    "n-gram model. Sampling from multinomial distribution can be done using a\n",
    "predefined ​function ​. Note, 5-10 sentences would suffice for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accepts integer values as the input argument(for example model_name=1 corresponds to unigram)\n",
    "# model_name=n, in general generates sentences using n-gram model(n=2,3,4....)\n",
    "# And generates sentences by utilizing MLEs from specified n-gram model using the corpus whole_text\n",
    "\n",
    "# Size is the optional argument which defines number of n-grams to choose for sentence formation and can be \n",
    "# chaged to generate desired sentences having specific number of n-grams\n",
    "\n",
    "# Assumption:whole_text variable defined earlier in this notebook is availble and that is the case if notebook is \n",
    "# run sequentially\n",
    "def Generator(model_name,size=150):\n",
    "    random.seed(3)\n",
    "    output = list(ngrams(whole_text.split(), model_name))\n",
    "    fdist1 = FreqDist(output)\n",
    "    mle_ngram={}\n",
    "    for key, value in fdist1.items():\n",
    "        mle_ngram[key]=fdist1[key]/len(output)\n",
    "\n",
    "    \n",
    "    ngram_words=[]\n",
    "    ngram_prob=[]\n",
    "    for key, value in mle_ngram.items():\n",
    "        ngram_words.append(key) \n",
    "        ngram_prob.append(value)\n",
    "    # function page:https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.multinomial.html\n",
    "    # One can play with 'Number of experiments' that is taken 20 here\n",
    "    word_idx_one_hot=np.random.multinomial(20, ngram_prob, size)\n",
    "    normal_idx=np.argmax(word_idx_one_hot,axis=-1)\n",
    "    sentences = ''\n",
    "    if model_name == 1:\n",
    "        for i in normal_idx:\n",
    "            sentences += ' '.join(ngram_words[i])+ ' '\n",
    "        print (sentences)\n",
    "    else:\n",
    "        for i in normal_idx:\n",
    "            sentences +=  ' '.join(ngram_words[i])+ ' '\n",
    "        print (sentences)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can’t the about the the and sure be in with the in the with the the it looked the in the had by the in very I it of ‘for the to of people the the the as an at way sadly. in ‘Well! the and the the of the she the water very of the muchness?’ a of the going one and and on the trembling YOUR The was the to the the of was thought I the the the arms, said in Turtle.’ the the in afterwards, size: the the the the the the Turtle. in she the a the to and officer and must the said the the said had the ‘All the very of the him the of said of it the in and the the the to Hatter: quite a the all a and you the the a the the people the little VI. said \n"
     ]
    }
   ],
   "source": [
    "# Examples of using the function 'Generator(model_name,size=150)'\n",
    "# Use unigram model with 150 unigrams \n",
    "Generator(1,size=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not a melancholy any volunteers of the all round described in M--’ ‘Why she, and there were did not had happened. ‘Take some under the Gryphon. ‘I the jurymen Alice could speed back with the it would the first upon it. by the an M, what a own courage. wrapping itself things!’ Alice about it, under the she went into a indeed!’ said twelve creatures,’ suppose you’ll far,’ said to twenty sell you Alice doubtfully: by the ‘I’m sure it--once more life before, they WOULD man, your house opened, course you me executed, must be must be to change round face, was lying by the here! It’ll ‘We called came rattling errors, a and no the door. it had the puppy order of said--’ ‘Get her look I can’t every now That he ask help guinea-pigs!’ thought must be dear quiet out with in?’ ‘There whiles.’ ‘Then to this sneeze of reach at curious dream!’ her pocket, ‘Please, then,’ without knowing them, I wits!’ So short remarks, at first, you dear difficulty was, of every the sudden unhappy at wonder?’ And think you you could there were to dull me! There now, Five! said the under the looking uneasily to Alice it had the way thimble, looking copy it, yet you other copies in Wonderland so that I or Alice desperately: official Project of beautiful Mouse gave flown into meal, and sort. Next make one up into much of listen to said the was dreadfully a dreadful to get of Hearts, thought Alice, I didn’t,’ wouldn’t have did you round face, plan, no asked another sentenced were could manage not, could are they reach at it had a frog reach at up I *** END ‘DRINK ME’ dear?’ it flamingo: she go to her anger she went them!’ Alice \n"
     ]
    }
   ],
   "source": [
    "# Examples of using the function 'Generator(model_name,size=150)'\n",
    "# Use unigram model with 150 bigrams \n",
    "Generator(2,size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on the door down and began floor, and a as mouse-traps, and one only knew completely. Very soon a deal faster now,’ thought Alice, game.’ The Queen opportunity for repeating a hoarse, feeble anxiously. ‘Yes,’ said on the door smaller, and being them round as to ear. ‘Please it away or personal remarks now?’ and donations from are located also paws and washing whole head appeared, poor man, your I will tell once; but, alas tears, but said Alice to herself. to see you begin with; and had!’ ‘Oh, I’ve tale, perhaps even sight before the on. ‘I do,’ medium, a computer and no one absence, and were “Come up again, the country is, incomplete, inaccurate or wags its tail ‘Come on!’ cried the name again!’ was, that she network of volunteer * * * head must be miles down, I and went on won’t do a following sentence, with or Longitude either, head off outside,’ seen them, of were doors all * * * in my own occurred to her * * * such a curious DON’T know,’ said affectionately into Alice’s, likely it can * * * out a race-course, the Nile On it: there were finger, as he Gutenberg” is a of justice before, a well?’ The some time without when Alice had heard a little gone across to affectionately into Alice’s, argument was, that when it’s angry, neatly spread his always ready to of exporting a lefthand bit of you know, upon ‘That depends a * * * HEARTS. Alice was * * * they COULD! I’m the sounds will ought! And when Soo--oop! Soo--oop of Hare. ‘Exactly so,’ the pictures of was high time avoid shrinking away for two reasons. witness.’ ‘Well, if out, at the be all day it was, even the shore. CHAPTER as mouse-traps, and cards!’ At this ‘they’d have been be on the learn! Oh, I you see, Alice she crossed her came the guests, hair that WOULD thing, and she well without--Maybe it’s the room, when Turtle said: ‘I’m at no cost it! Oh dear! chrysalis--you will some must cross-examine THIS witness.’ And he * * * ‘for it might was her dream:-- to disagree with with a whiting. King. Here one the floor: in eyes were getting any good reason, narrow, to be could let you the Fish-Footman was arm that was and it set ready to play Here was another isn’t usual, you and get ready herself, and began thought Alice. ‘I’m growing larger and could not, would consultation about this, a very short to change the efforts and donations I shall be presented the thimble, conversation. ‘Are you--are piece out of again. Alice waited me out of \n"
     ]
    }
   ],
   "source": [
    "# Examples of using the function 'Generator(model_name,size=150)'\n",
    "# Use trigram model with 150 trigrams \n",
    "Generator(3,size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it teases.’ CHORUS. (In was gone across to looked along the passage in the U.S. unless high, and her face may stand down,’ continued on, ‘you see, a the Project Gutenberg Literary Hatter: ‘it’s very easy charities and charitable donations this young lady to she thought. ‘But everything’s please go on!’ Alice way to explain it Alice. ‘But you’re so knife, it usually bleeds; but she had not Redistribution is subject to this young lady to moral of that is--“Birds in the act of off, and found herself are “much of a got a moral, if the look of the into her head. ‘If with the other players, to introduce some other takes some time,’ interrupted what a wonderful dream not otherwise than what or later. However, this any of them. ‘I’m again into its nest. domain (does not contain larger and smaller, and first really clever thing ‘Does the boots and please, if the Mock talk about cats or asleep. ‘After that,’ continued perhaps it was only on it were white, United States. Compliance requirements noise inside, no one the air. She did is blown out, for cup of tea, and the Gryphon repeated impatiently: suddenly upon an open Alice looked round, eager hair that curled all are “much of a them a railway station.) are ferrets! Where CAN your pardon!’ said the having the sentence first!’ world she was to her own children. ‘How the full Project Gutenberg-tm all a pity. I at all. ‘But perhaps ‘but I’m not looking sir’ said Alice, ‘because are in a constant getting up and saying, little magic bottle had ‘And ever since that,’ eyes, for it was and many fees to the name of the went on eagerly: ‘There said the Hatter with running about in all main PG search facility: ‘The trial’s beginning!’ was to feel a little the crown. William’s conduct it was over at the Gryphon. ‘How the and loving heart of forth in the General to find quite a Dormouse! Turn that Dormouse Soup! Who cares for to the game, the the March Hare. ‘Exactly in the same format the things I used glass. ‘What a number a LITTLE larger, sir, me a pair of none, Why, I do began again: ‘Ou est ‘It tells the day she could do, lying your history, she do.’ on crying in this am I to do?’ mad. You’re mad.’ ‘How again. ‘Mine is a you may stand down,’ seemed to think that Northumbria, declared for him: was going off into sir’ said Alice, ‘because chimney close above her: very carefully, nibbling first it as you say asked triumphantly. Alice did them, they were trying joined in chorus, ‘Yes, round her, about four dear, how puzzling it again into its nest. and hurried off to that better,’ Alice said FULL PROJECT GUTENBERG LICENSE 4557 Melan Dr. S. the Knave ‘Turn them might appear to others know all sorts of I’ll try and say the tail, and ending behind us, and he’s but it’s an arm trademark, and any other to the little door: sorrow, you know. Come ‘it’s very easy to a sudden leap out if the Mock Turtle someone to listen to not venture to go ‘I’m a poor man,’ see what was on ‘it’s very easy to Mock Turtle at last, Alice said very politely, the Mouse, who seemed no right to grow the Project Gutenberg-tm concept was linked into hers in the distance, and Duchess: you’d better ask This file should be turned the corner, but ‘at least--at least I not venture to go lay far below her. \n"
     ]
    }
   ],
   "source": [
    "# Examples of using the function 'Generator(model_name,size=150)'\n",
    "# Use quadgram model with 150 quadgrams \n",
    "Generator(4,size=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Probability(sentence,model_name): Compute the probability of a given sentence\n",
    "in log-space. Note you can provide any sentence, however, a random sentence\n",
    "will mostly lead to zero probability. The better idea is to take sentences from the\n",
    "corpus itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here n is the model name. whole_text as defined earlier is just passed for the completeness purpose\n",
    "def Probability(sentence,n,whole_text):\n",
    "    #print(sentence)\n",
    "    if n==1:\n",
    "        try:\n",
    "            split_sen = list(ngrams(sentence.split(), 1))\n",
    "           \n",
    "            output = list(ngrams(whole_text.split(), 1))\n",
    "            fdist1 = FreqDist(output)\n",
    "            mle_unigram={}\n",
    "            for key, value in fdist1.items():\n",
    "                mle_unigram[key]=fdist1[key]/len(output)\n",
    "\n",
    "            prob_sent=1\n",
    "            for key in split_sen:\n",
    "                prob_sent *= mle_unigram[key]\n",
    "            prob_sent=np.array(prob_sent)\n",
    "            prob_sent_log = np.log(prob_sent)# grams prob in log space\n",
    "            print('Probability of the given sentence (in log space) using n-grams is: {}'.format(prob_sent_log))\n",
    "        except:\n",
    "            prob_sent_log=0\n",
    "            print('Probability of the given sentence is: {}'.format(prob_sent_log))\n",
    "  \n",
    "    else:\n",
    "        output_n = list(ngrams(whole_text.split(), n))\n",
    "        fdist1_n = FreqDist(output_n)\n",
    "\n",
    "        output_n_1 = list(ngrams(whole_text.split(),n-1))\n",
    "        fdist1_n_1 = FreqDist(output_n_1)\n",
    "\n",
    "        n=n-1\n",
    "        split_sen=sentence.split()\n",
    "        prob_sent = []\n",
    "        try:\n",
    "            for i in range(n,len(split_sen)-1):\n",
    "\n",
    "                nk_key = tuple([split_sen[k] for k in range(i-n,i+1)])\n",
    "                #print(nk_key)\n",
    "                nk_1_key = tuple([split_sen[k] for k in range(i-n,i)])\n",
    "                #print(nk_1_key)\n",
    "\n",
    "                ci = fdist1_n[nk_key]\n",
    "                #print(ci)\n",
    "                cj = fdist1_n_1[nk_1_key]\n",
    "                #print(cj)\n",
    "                prob_sent.append(float(ci) / cj)\n",
    "            prob_sent = np.array(prob_sent)\n",
    "            prob_sent = np.log(prob_sent)# grams prob in log space\n",
    "            prob_sent_all  = np.sum(prob_sent)# sentence prob in log space\n",
    "            print('Probability (in log space) of the n-grams is: ',prob_sent)\n",
    "            print('Probability of the given sentence (in log space) using n-grams is: {}'.format(prob_sent_all))\n",
    "\n",
    "        except:\n",
    "            prob_sent_all=0\n",
    "            print('Probability of the whole sentence is: ',prob_sent_all)\n",
    "        \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of the given sentence (in log space) using n-grams is: -229.8932821768834\n"
     ]
    }
   ],
   "source": [
    "#sentence='''She took down a jar from one of the shelves '''\n",
    "sentence='''There was nothing so VERY remarkable in that; nor did Alice think it so\n",
    "VERY much out of the way to hear the Rabbit say to itself, ‘Oh dear!\n",
    "Oh dear! I shall be late!’'''\n",
    "Probability(sentence,1,whole_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-Implement add-1 smoothing for bigram model and give 2-3 examples where drastic change in\n",
    "the count occurs post-smoothing. Can you explain this drastic change in a sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of a sentence After Smoothing 2.06608922172e-131\n",
      "Bigram Count Before Smoothing: [ 14   4   1   5   1   1   1   1   1   1   1   3   3   5   1   1  36 152\n",
      "   8   4   5   5  15   1   3   2   1   1   1   2   4  12   4   1]\n",
      "Effective Count After Smoothing: [0.010683036017092857, 0.05521245888433913, 0.0014921829958964969, 0.021103182386959317, 0.0008141941174475014, 0.00013574507075711812, 0.026853277974954796, 6.787483879725786e-05, 0.00013574507075711812, 0.0033881077418261903, 0.01488917334770599, 0.005016609043454681, 0.04775158445390832, 0.021103182386959317, 0.0008141941174475014, 0.0027790957771300752, 0.12140585887287735, 3.033432021556169, 0.48109479906196795, 0.006609273318872017, 0.15338316026192209, 0.0030529172320217096, 0.8552796427768319, 0.001966501661354852, 0.0047457627118644066, 0.07669158013096104, 0.000271471716040585, 0.00013574507075711812, 0.0006107077424170455, 0.0005089921954530031, 0.0015267693560426139, 0.11370899915895712, 0.0038998914812805206, 0.01039873054458287]\n"
     ]
    }
   ],
   "source": [
    "# Implemetation of add-1 smoothing for bigram model \n",
    "output_uni = list(ngrams(whole_text.split(), 1))\n",
    "fdist1_uni = FreqDist(output_uni)\n",
    "\n",
    "output_bi = list(ngrams(whole_text.split(), 2))\n",
    "fdist1_bi = FreqDist(output_bi)\n",
    "\n",
    "mod_v=len(list(ngrams(whole_text.split(), 1)))\n",
    "\n",
    "\n",
    "##### Three Sentences are given for seeing the results as asked in question. Some other test_sentences can also be given\n",
    "#test_sentence='''She took down a jar from one of the shelves as she passed'''\n",
    "#test_sentence='''She took down a jar from one of the roads as she passed'''\n",
    "test_sentence='''There was nothing so VERY remarkable in that; nor did Alice think it so\n",
    "VERY much out of the way to hear the Rabbit say to itself, ‘Oh dear!\n",
    "Oh dear! I shall be late!’'''\n",
    "\n",
    "\n",
    "#output = list(ngrams(test_sentence.split(), 1))\n",
    "output=test_sentence.split()\n",
    "\n",
    "pws = [] # for probability of a sentence\n",
    "bigram_count=[]\n",
    "c_star=[] # Effective Count after smoothing\n",
    "n= 1 # n=1 for bigram\n",
    "for i in range(n,len(output)):\n",
    "    \n",
    "    nk_key = tuple([output[k] for k in range(i-n,i+1)])\n",
    "    #print(nk_key)\n",
    "    nk_1_key = tuple([output[k] for k in range(i-n,i)])\n",
    "    #print(nk_1_key)\n",
    "    \n",
    "    ci = fdist1_bi[nk_key]\n",
    "    bigram_count.append(ci)\n",
    "    #print(ci)\n",
    "    cj = fdist1_uni[nk_1_key]\n",
    "    #print(cj)\n",
    "    \n",
    "    p_mle=(float(ci)+1) / (cj+mod_v)\n",
    "    pws.append(p_mle)\n",
    "    \n",
    "   \n",
    "    c_star.append(float(p_mle*cj))\n",
    "    \n",
    "\n",
    "pws = np.array(pws)    \n",
    "pws_final  = np.prod(pws)\n",
    "\n",
    "print('probability of a sentence After Smoothing',pws_final)\n",
    "bigram_count=np.array(bigram_count)\n",
    "print(\"Bigram Count Before Smoothing:\", bigram_count)\n",
    "print(\"Effective Count After Smoothing:\", c_star)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ques: Drastic change in count?\n",
    "\n",
    "Ans: In add-1 smoothing, unseen n-grams are given very high weights which results in the drastic change in count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6- Do you observe the constant discounting value ‘d’ by implementing Good-turing smoothing\n",
    "technique? If yes, what is the value of ‘d’?\n",
    "Hint: ​You can check for n-grams having original counts between 1-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "53\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "C_star:  [0.22292598112270243, 1.0629526462395542, 1.4528301886792452, 4.1341991341991342, 3.424083769633508, 4.5596330275229358, 6.3098591549295771, 5.4642857142857144, 7.3529411764705879]\n",
      "P_star: [7.5657892795758505e-06, 3.6075094051910882e-05, 4.930698077988275e-05, 0.00014030881161374966, 0.00011620851076305813, 0.00015474743008732177, 0.00021414760410417706, 0.00018545004969576495, 0.00024954831754524307]\n",
      "c-c*= [ 0.77707402  0.93704735  1.54716981 -0.13419913  1.57591623  1.44036697\n",
      "  0.69014085  2.53571429  1.64705882]\n"
     ]
    }
   ],
   "source": [
    "# Good-turing smoothing technique\n",
    "n=2\n",
    "output_n = list(ngrams(whole_text.split(),n ))\n",
    "fdist1_n = FreqDist(output_n)\n",
    "\n",
    "# Compute Frequency of Frequency N_c\n",
    "freq_freq=FreqDist(fdist1_n.values())\n",
    "c=np.array(list(freq_freq.keys()))\n",
    "print(len(c))\n",
    "N_c=np.array(list(freq_freq.values()))\n",
    "print(len(N_c))\n",
    "\n",
    "\n",
    "c=c[:10]\n",
    "N_c=N_c[:10]\n",
    "\n",
    "N=len(list(ngrams(whole_text.split(), 1)))\n",
    "\n",
    "print(c)\n",
    "\n",
    "\n",
    "c_star=[] #For Effective Count\n",
    "P_star=[]#For Effective Probability\n",
    "for i in range(len(c)-1):\n",
    "    #print(i)\n",
    "    tmp=((c[i]+1)*N_c[i+1])/N_c[i]\n",
    "    c_star.append(tmp)\n",
    "    P_star.append(tmp/N)\n",
    "print('C_star: ', c_star)\n",
    "print('P_star:',P_star)\n",
    "print('c-c*=',np.array(c[:9])-np.array(c_star))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the current corpus for the for n-grams having original counts between 1-10, in most cases is close to 1.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-Compute the perplexity value for the test dataset for the bigram model using add-1 and\n",
    "Good-turing. Which performs better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(test_dataset, model_name, smoothing):\n",
    "    split_sen = test_dataset.split()\n",
    "    output_n = list(ngrams(whole_text.split(), model_name))\n",
    "    fdist1_n = FreqDist(output_n)\n",
    "\n",
    "    output_n_1 = list(ngrams(whole_text.split(),model_name-1))\n",
    "    fdist1_n_1 = FreqDist(output_n_1)\n",
    "\n",
    "    n=model_name-1\n",
    "    if smoothing=='add-1':\n",
    "        mod_v=len(list(ngrams(whole_text.split(), 1)))\n",
    "        pws = []\n",
    "        for i in range(n,len(split_sen)-1):\n",
    "\n",
    "            nk_key = tuple([split_sen[k] for k in range(i-n,i+1)])\n",
    "            #print(nk_key)\n",
    "            nk_1_key = tuple([split_sen[k] for k in range(i-n,i)])\n",
    "            #print(nk_1_key)\n",
    "\n",
    "            ci = fdist1_n[nk_key]\n",
    "            #print(ci)\n",
    "            cj = fdist1_n_1[nk_1_key]\n",
    "            #print(cj)\n",
    "            pws.append(1/(float(ci)+1) / (cj+mod_v))\n",
    "    elif smoothing=='gt':\n",
    "        # Good-turing smoothing technique\n",
    "        pws = []\n",
    "        for i in range(n,len(split_sen)-1):\n",
    "\n",
    "            nk_key = tuple([split_sen[k] for k in range(i-n,i+1)])\n",
    "            #print(nk_key)\n",
    "            nk_1_key = tuple([split_sen[k] for k in range(i-n,i)])\n",
    "            #print(nk_1_key)\n",
    "            \n",
    "            ci = fdist1_n[nk_key]\n",
    "            #print(ci)\n",
    "            cj = fdist1_n_1[nk_1_key]\n",
    "            #print(cj)\n",
    "            \n",
    "            pws.append(1/(float(ci)-1.6) / (cj)) # subtract the discounting value computed from 'GT (Good Turing)'\n",
    "\n",
    "        \n",
    "\n",
    "    pws = np.array(pws)\n",
    "    print(pws)\n",
    "    pws = np.prod(pws)# grams prob in log space\n",
    "    N=len(list(ngrams(whole_text.split(),1)))\n",
    "    perplexity = np.power(pws, 1/float(N))\n",
    "    print('Perplexity of the sentence with {} smoothing is: {}' .format(smoothing,perplexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -5.05050505e-02  -7.24637681e-02   5.41125541e-03  -2.51762336e-03\n",
      "  -8.33333333e-01   9.25925926e-03   6.60851176e-04   1.11559332e-05\n",
      "  -1.00160256e-03  -1.66666667e+00   7.61243567e-05]\n",
      "Perplexity of the sentence with gt smoothing is: 0.9980916752322215\n"
     ]
    }
   ],
   "source": [
    "test_dataset='''She took down a jar from one of the shelves as she passed'''\n",
    "model_name=2 # integer value >=2 (n=2 for bigram,n=3 for trigram, so on )\n",
    "smoothing='gt'\n",
    "perplexity(test_dataset, model_name, smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.69503017e-05   1.69560499e-05   6.77002234e-06   1.65964085e-05\n",
      "   1.69681338e-05   6.77736361e-06   1.53858936e-06   2.17422831e-07\n",
      "   1.60621928e-05   1.69687097e-05   6.01027998e-07]\n",
      "Perplexity of the sentence with add-1 smoothing is: 0.9955017677299063\n"
     ]
    }
   ],
   "source": [
    "test_dataset='''She took down a jar from one of the shelves as she passed'''\n",
    "model_name=2 # integer value >=2 (n=2 for bigram,n=3 for trigram, so on )\n",
    "smoothing='add-1'\n",
    "perplexity(test_dataset, model_name, smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the current corpus for the for bigram model Perplexity of the sentence with gt smoothing is approximately equal to the Perplexity of the sentence with add-1 smoothing.\n",
    "So there is no conclusive evidence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
